{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"authorship_tag":"ABX9TyOMMp73qf0Gg34+kyDMHmem"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"VqMPARWlcwhX"},"source":["import torch\n","import torchvision\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torchvision import transforms, datasets\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","\n","# 하이퍼파라미터\n","EPOCH = 10\n","BATCH_SIZE = 64\n","USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n","print(\"다음 기기로 학습합니다:\", DEVICE)\n","\n","\n","# Fashion MNIST 학습 데이터셋\n","trainset = datasets.FashionMNIST(\n","    root      = './.data/', \n","    train     = True,\n","    download  = True,\n","    transform = transforms.ToTensor()\n",")\n","\n","train_loader = torch.utils.data.DataLoader(\n","    dataset     = trainset,\n","    batch_size  = BATCH_SIZE,\n","    shuffle     = True,\n","    num_workers = 2\n",")\n","\n","\n","class Autoencoder(nn.Module):\n","    def __init__(self):\n","        super(Autoencoder, self).__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Linear(28*28, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 12),\n","            nn.ReLU(),\n","            nn.Linear(12, 3),   # 입력의 특징을 3차원으로 압축합니다\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(3, 12),\n","            nn.ReLU(),\n","            nn.Linear(12, 64),\n","            nn.ReLU(),\n","            nn.Linear(64, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 28*28),\n","            nn.Sigmoid(),       # 픽셀당 0과 1 사이로 값을 출력합니다\n","        )\n","\n","    def forward(self, x):\n","        encoded = self.encoder(x)\n","        decoded = self.decoder(encoded)\n","        return encoded, decoded\n","\n","\n","autoencoder = Autoencoder().to(DEVICE)\n","optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.005)\n","criterion = nn.MSELoss()\n","\n","\n","def add_noise(img):\n","    noise = torch.randn(img.size()) * 0.2\n","    noisy_img = img + noise\n","    return noisy_img\n","\n","\n","def train(autoencoder, train_loader):\n","    autoencoder.train()\n","    avg_loss = 0\n","    for step, (x, label) in enumerate(train_loader):\n","        noisy_x = add_noise(x)  # 입력에 노이즈 더하기\n","\n","        x = x.view(-1, 28*28).to(DEVICE)\n","        noisy_x = noisy_x.view(-1, 28*28).to(DEVICE)\n","        label = label.to(DEVICE)\n","        \n","        encoded, decoded = autoencoder(noisy_x)\n","\n","        loss = criterion(decoded, x)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        avg_loss += loss.item()\n","    return avg_loss / len(train_loader)\n","\n","\n","for epoch in range(1, EPOCH+1):\n","    loss = train(autoencoder, train_loader)\n","    print(\"[Epoch {}] loss:{}\".format(epoch, loss))\n","    # 이번 예제에선 학습시 시각화를 건너 뜁니다\n","\n","\n","# # 이미지 복원 시각화 하기\n","\n","# 모델이 학습시 본적이 없는 데이터로 검증하기 위해 테스트 데이터셋을 가져옵니다.\n","testset = datasets.FashionMNIST(\n","    root      = './.data/', \n","    train     = False,\n","    download  = True,\n","    transform = transforms.ToTensor()\n",")\n","\n","# 테스트셋에서 이미지 한장을 가져옵니다.\n","sample_data = testset.data[0].view(-1, 28*28)\n","sample_data = sample_data.type(torch.FloatTensor)/255.\n","\n","# 이미지를 add_noise로 오염시킨 후, 모델에 통과시킵니다.\n","original_x = sample_data[0]\n","noisy_x = add_noise(original_x).to(DEVICE)\n","_, recovered_x = autoencoder(noisy_x)\n","\n","\n","f, a = plt.subplots(1, 3, figsize=(28, 28))\n","\n","# 시각화를 위해 넘파이 행렬로 바꿔줍니다.\n","original_img = np.reshape(original_x.to(\"cpu\").data.numpy(), (28, 28))\n","noisy_img = np.reshape(noisy_x.to(\"cpu\").data.numpy(), (28, 28))\n","recovered_img = np.reshape(recovered_x.to(\"cpu\").data.numpy(), (28, 28))\n","\n","# 원본 사진\n","a[0].set_title('Original')\n","a[0].imshow(original_img, cmap='gray')\n","\n","# 오염된 원본 사진\n","a[1].set_title('Noisy')\n","a[1].imshow(noisy_img, cmap='gray')\n","\n","# 복원된 사진\n","a[2].set_title('Recovered')\n","a[2].imshow(recovered_img, cmap='gray')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8qHrJLjic0I_"},"source":[""],"execution_count":null,"outputs":[]}]}